# Dec207Hub Backend Main Application
# FastAPI ë©”ì¸ ì•± ë° ì—”ë“œí¬ì¸íŠ¸

import os
import httpx
import uvicorn
from datetime import datetime
from typing import Dict, Any
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from config import (
    OLLAMA_BASE_URL, DEFAULT_MODEL, SERVER_HOST, SERVER_PORT, LOG_LEVEL
)
from models import ChatRequest, ChatResponse, HealthResponse, ModelsResponse
from logger import chat_logger
from chat_handler import chat_with_ollama
from websocket_handler import websocket_endpoint, manager

# FastAPI ì•± ìƒì„±
app = FastAPI(title="Dec207Hub API", version="1.0.0")

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# WebSocket ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡ (ì •ì  íŒŒì¼ë³´ë‹¤ ë¨¼ì €)
app.websocket("/ws")(websocket_endpoint)

# frontend ë””ë ‰í† ë¦¬ë¥¼ ì •ì  íŒŒì¼ë¡œ ì„œë¹™
frontend_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "frontend")
app.mount("/", StaticFiles(directory=frontend_path, html=True), name="static")

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        # Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5.0)
            ollama_status = "connected" if response.status_code == 200 else "disconnected"
    except Exception as e:
        ollama_status = f"error: {str(e)}"
    
    return HealthResponse(
        server="running",
        ollama=ollama_status,
        timestamp=datetime.now().isoformat(),
        active_connections=len(manager.active_connections)
    )

@app.get("/models", response_model=ModelsResponse)
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ëª©ë¡"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=10.0)
            if response.status_code == 200:
                data = response.json()
                models = [model["name"] for model in data.get("models", [])]
                return ModelsResponse(models=models, default=DEFAULT_MODEL)
            else:
                return ModelsResponse(
                    models=[], 
                    default=DEFAULT_MODEL,
                    error="Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                )
    except Exception as e:
        return ModelsResponse(
            models=[], 
            default=DEFAULT_MODEL,
            error=f"ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request_body: ChatRequest, request: Request):
    """REST APIë¥¼ í†µí•œ ì±„íŒ…"""
    message = request_body.message
    model = request_body.model or DEFAULT_MODEL
    conversation_history = request_body.conversation_history or []
    
    if not message:
        return ChatResponse(
            user_message="",
            ai_response="ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤",
            model=model,
            response_time=0.0,
            timestamp=datetime.now().isoformat()
        )
    
    # í´ë¼ì´ì–¸íŠ¸ IP ì¶”ì¶œ
    user_ip = chat_logger.get_client_ip(request)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ë¡œê¹…
    chat_logger.log_message(user_ip, "user", message)
    
    # AI ì‘ë‹µ ìƒì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
    start_time = datetime.now()
    ai_response = await chat_with_ollama(message, model, conversation_history)
    response_time = (datetime.now() - start_time).total_seconds()
    
    # AI ì‘ë‹µ ë¡œê¹…
    chat_logger.log_message(user_ip, "assistant", ai_response, response_time, model)
    
    return ChatResponse(
        user_message=message,
        ai_response=ai_response,
        model=model,
        response_time=response_time,
        timestamp=datetime.now().isoformat()
    )

if __name__ == "__main__":
    print("ğŸš€ Dec207Hub API ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ“ URL: http://192.168.0.7:8000")
    print("ğŸ”Œ WebSocket: ws://192.168.0.7:8000/ws")
    print("ğŸ“‹ API ë¬¸ì„œ: http://192.168.0.7:8000/docs")
    print("ğŸ“± ëª¨ë°”ì¼ ì ‘ì† ì§€ì›: WebSocket ì—°ê²° ê°€ëŠ¥")
    print(f"ğŸ“ ì±„íŒ… ë¡œê·¸ ì €ì¥ ìœ„ì¹˜: {chat_logger.log_dir}")
    print("=" * 60)
    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT, log_level=LOG_LEVEL.lower())
