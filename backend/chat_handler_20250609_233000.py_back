# Dec207Hub Backend Chat Handler
# Ollamaì™€ì˜ ì±„íŒ… ì²˜ë¦¬ ë° MCP ë„êµ¬ ì—°ë™

import json
import httpx
import logging
import re
from datetime import datetime
from typing import List, Dict, Any
from config import (
    OLLAMA_BASE_URL, DEFAULT_MODEL, HTTP_TIMEOUT, MAX_CONVERSATION_HISTORY,
    MAX_CONTEXT_MESSAGES, MAX_MESSAGE_LENGTH, AI_TEMPERATURE, AI_TOP_P, AI_REPEAT_PENALTY
)
from mcp_manager import get_mcp_tools, execute_mcp_tool

logger = logging.getLogger(__name__)

async def chat_with_ollama(message: str, model: str = DEFAULT_MODEL, 
                          conversation_history: List[Dict] = None) -> str:
    """ì±„íŒ… í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì½”ë“œ í¬ë§¤íŒ…ì„ ì§€ì›í•˜ë„ë¡ Ollamaì™€ ì±„íŒ… + MCP Tool Calling"""
    try:
        async with httpx.AsyncClient(timeout=HTTP_TIMEOUT) as client:
            # MCP ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            mcp_tools = await get_mcp_tools()
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± - ì¤‘ë³µ ë°©ì§€ ë° ìµœì í™”
            context_prompt = build_context_prompt(conversation_history)
            
            # ë„êµ¬ ëª©ë¡ ì„¤ëª… ì¶”ê°€
            tools_description = build_tools_description(mcp_tools)
            
            # ê°œì„ ëœ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ - ëŒ€í™” ì—°ì†ì„± + MCP ë„êµ¬ ì§€ì›
            enhanced_prompt = build_enhanced_prompt(context_prompt, tools_description, message)
            
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": enhanced_prompt
                    }
                ],
                "tools": mcp_tools,
                "stream": False,
                "options": {
                    "temperature": AI_TEMPERATURE,
                    "top_p": AI_TOP_P,
                    "repeat_penalty": AI_REPEAT_PENALTY
                }
            }
            
            logger.info(f"Ollamaì— ìš”ì²­ ì „ì†¡: {message[:50]}...")
            response = await client.post(f"{OLLAMA_BASE_URL}/api/chat", json=payload)
            
            if response.status_code == 200:
                data = response.json()
                
                # ë””ë²„ê¹…: ì „ì²´ ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
                logger.info(f"ğŸ” Ollama ì‘ë‹µ êµ¬ì¡°: {json.dumps(data, indent=2, ensure_ascii=False)[:500]}...")
                
                # Tool calls ì²˜ë¦¬
                tool_results = await process_tool_calls(data)
                
                # AI ì‘ë‹µ ìƒì„±
                ai_response = data.get("message", {}).get("content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.").strip()
                
                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‘ë‹µì— ì¶”ê°€
                if tool_results:
                    ai_response += build_tool_results_text(tool_results)
                
                # ë‹µë³€ í›„ì²˜ë¦¬: ê¸°ë³¸ì ì¸ ì •ë¦¬
                ai_response = clean_ai_response(ai_response)
                
                logger.info(f"Ollama ì‘ë‹µ ë°›ìŒ (ë„êµ¬ {len(tool_results)}ê°œ ì‹¤í–‰): {ai_response[:50]}...")
                return ai_response
            else:
                logger.error(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                return f"AI ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ìƒíƒœ ì½”ë“œ: {response.status_code})"
                
    except httpx.TimeoutException:
        logger.error("Ollama ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        return "AI ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    except Exception as e:
        logger.error(f"Ollama í†µì‹  ì˜¤ë¥˜: {str(e)}")
        return f"AI ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def build_context_prompt(conversation_history: List[Dict]) -> str:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    context_prompt = ""
    if conversation_history and len(conversation_history) > 0:
        # ì¤‘ë³µ ë©”ì‹œì§€ ì œê±° ë° ìµœê·¼ 4ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
        unique_history = []
        seen_messages = set()
        
        for msg in reversed(conversation_history[-MAX_CONVERSATION_HISTORY:]):
            msg_content = msg.get('content', '').strip()
            if msg_content and msg_content not in seen_messages:
                unique_history.append(msg)
                seen_messages.add(msg_content)
                if len(unique_history) >= MAX_CONTEXT_MESSAGES:
                    break
        
        if unique_history:
            context_prompt = "ì´ì „ ëŒ€í™”:\n"
            for msg in reversed(unique_history):  # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
                role_display = "ì‚¬ìš©ì" if msg.get('role') == 'user' else "AI"
                content = msg.get('content', '')[:MAX_MESSAGE_LENGTH]  # ë‚´ìš© ê¸¸ì´ ì œí•œ
                context_prompt += f"{role_display}: {content}\n"
            context_prompt += "\ní˜„ì¬ ì§ˆë¬¸ì— ì§‘ì¤‘í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
    
    return context_prompt

def build_tools_description(mcp_tools: List[Dict]) -> str:
    """ë„êµ¬ ëª©ë¡ ì„¤ëª… êµ¬ì„±"""
    tools_description = ""
    if mcp_tools:
        tools_description = "\n\n**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:**\n"
        for tool in mcp_tools:
            tool_name = tool["function"]["name"]
            tool_desc = tool["function"]["description"]
            tools_description += f"- {tool_name}: {tool_desc}\n"
        tools_description += "\ní•„ìš”í•œ ê²½ìš° ìœ„ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
    
    return tools_description

def build_enhanced_prompt(context_prompt: str, tools_description: str, message: str) -> str:
    """ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    return f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:

**ë‹µë³€ ê·œì¹™:**
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€
2. ì •ì¤‘í•œ ì–¸ì–´ ì‚¬ìš©
3. ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€
4. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
5. ì½”ë“œëŠ” ```ë¡œ ê°ì‹¸ì„œ ì‘ì„±
6. ì¤‘ìš”í•œ ë‚´ìš©ì€ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
7. ëª©ë¡ì€ - ë˜ëŠ” 1. 2. 3. í˜•ì‹ ì‚¬ìš©
8. ê³¼ë„í•œ íŠ¹ìˆ˜ê¸°í˜¸ (â˜…â˜†â– â—â—‹ ë“±) ì‚¬ìš© ê¸ˆì§€
**ë„êµ¬ ì‚¬ìš© ê·œì¹™:**
9. ë„êµ¬ëŠ” ì‚¬ìš©ìê°€ ëª…í™•íˆ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
10. ë‹¨ìˆœí•œ ì¸ì‚¬ë§(ì•ˆë…•, ì•ˆë…•í•˜ì„¸ìš”, í•˜ì´, hello ë“±)ì—ëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
11. ì¼ë°˜ì ì¸ ì§ˆë¬¸ì´ë‚˜ ëŒ€í™”ì—ëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
12. ì‚¬ìš©ìê°€ "ë¸”ë Œë”ì—ì„œ", "ìœ ë‹ˆí‹°ì—ì„œ", "ì„œë²„ ìƒíƒœ" ë“± êµ¬ì²´ì ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©ì„ ìš”ì²­í•  ë•Œë§Œ ì‚¬ìš©

**ì‚¬ì‹¤ í™•ì¸ ê·œì¹™:**
13. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•Šê³  "ì •í™•í•œ ì •ë³´ë¥¼ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€
14. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ìˆ ì´ë‚˜ í”„ë¡œí† ì½œì„ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠìŒ
15. MCP ê´€ë ¨ ì§ˆë¬¸ì€ ì‹¤ì œ Anthropic MCP í”„ë¡œí† ì½œ ì •ë³´ë§Œ ì œê³µ

{tools_description}

{context_prompt}í˜„ì¬ ì§ˆë¬¸: {message}

AI ë‹µë³€:"""

async def process_tool_calls(data: Dict) -> List[Dict]:
    """Tool calls ì²˜ë¦¬"""
    tool_calls = []
    
    # ë°©ë²• 1: ì§ì ‘ tool_calls í•„ë“œ
    if "tool_calls" in data:
        tool_calls = data["tool_calls"]
        logger.info(f"ğŸ”§ ë°©ë²•1 - tool_calls ë°œê²¬: {len(tool_calls)}ê°œ")
    
    # ë°©ë²• 2: message ë‚´ë¶€ì˜ tool_calls
    elif "message" in data and "tool_calls" in data["message"]:
        tool_calls = data["message"]["tool_calls"]
        logger.info(f"ğŸ”§ ë°©ë²•2 - message.tool_calls ë°œê²¬: {len(tool_calls)}ê°œ")
    
    # ë°©ë²• 3: messages ë°°ì—´ ë‚´ë¶€ í™•ì¸
    elif "messages" in data:
        for msg in data["messages"]:
            if "tool_calls" in msg:
                tool_calls = msg["tool_calls"]
                logger.info(f"ğŸ”§ ë°©ë²•3 - messages[].tool_calls ë°œê²¬: {len(tool_calls)}ê°œ")
                break
    
    logger.info(f"ğŸ”§ ìµœì¢… Tool calls: {len(tool_calls)}ê°œ")
    tool_results = []
    
    if tool_calls:
        logger.info(f"ğŸ”§ Tool calls ê°ì§€: {len(tool_calls)}ê°œ")
        
        for tool_call in tool_calls:
            try:
                function_info = tool_call.get("function", {})
                tool_name = function_info.get("name", "")
                tool_args = function_info.get("arguments", {})
                
                # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
                if isinstance(tool_args, str):
                    tool_args = json.loads(tool_args)
                
                logger.info(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name} - {tool_args}")
                
                # MCP ë„êµ¬ ì‹¤í–‰
                tool_result = await execute_mcp_tool(tool_name, tool_args)
                tool_results.append({
                    "tool_name": tool_name,
                    "result": tool_result
                })
                
            except Exception as e:
                logger.error(f"âŒ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜ {tool_name}: {e}")
                tool_results.append({
                    "tool_name": tool_name,
                    "result": {"success": False, "error": str(e)}
                })
    
    return tool_results

def build_tool_results_text(tool_results: List[Dict]) -> str:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í…ìŠ¤íŠ¸ êµ¬ì„±"""
    result_text = "\n\nğŸ”§ **ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:**\n"
    for tool_result in tool_results:
        tool_name = tool_result["tool_name"]
        result = tool_result["result"]
        
        if result.get("success", False):
            result_text += f"\nâœ… **{tool_name}**: {result.get('result', 'ì‹¤í–‰ ì™„ë£Œ')}\n"
        else:
            result_text += f"\nâŒ **{tool_name}**: {result.get('error', 'ì‹¤í–‰ ì‹¤íŒ¨')}\n"
    
    return result_text

def clean_ai_response(response: str) -> str:
    """ê¸°ë³¸ì ì¸ AI ì‘ë‹µ ì •ë¦¬"""
    # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
    response = response.replace('\n\n\n\n', '\n\n')
    
    # ì‹œì‘/ë ê³µë°± ì œê±°
    response = response.strip()
    
    # ê³¼ë„í•œ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
    response = re.sub(r'[\u2605\u2606\u25a0\u25cf\u25cb\u2661\u2665\u2668\u266a\u266b]{2,}', '', response)
    
    return response