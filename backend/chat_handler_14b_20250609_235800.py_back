# Dec207Hub Backend Chat Handler
# Qwen2.5-Coder-14B + Function Calling + ABAP ìµœì í™”

import json
import httpx
import logging
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
from config import (
    OLLAMA_BASE_URL, DEFAULT_MODEL, FALLBACK_MODEL, HTTP_TIMEOUT, 
    MAX_CONVERSATION_HISTORY, MAX_CONTEXT_MESSAGES, MAX_MESSAGE_LENGTH,
    AI_TEMPERATURE, AI_TOP_P, AI_REPEAT_PENALTY, AI_MAX_NEW_TOKENS,
    ENABLE_MCP, ENABLE_FUNCTION_CALLING, ENABLE_FACT_CHECK, UNCERTAINTY_THRESHOLD
)

logger = logging.getLogger(__name__)

async def chat_with_ollama(message: str, model: str = DEFAULT_MODEL, 
                          conversation_history: List[Dict] = None,
                          enable_tools: bool = True) -> str:
    """Qwen2.5-Coder-14Bì™€ ê³ ê¸‰ ì±„íŒ… - Function Calling ë° ABAP ìµœì í™”"""
    try:
        async with httpx.AsyncClient(timeout=HTTP_TIMEOUT) as client:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í™•ì¥ëœ íˆìŠ¤í† ë¦¬)
            context_prompt = build_enhanced_context_prompt(conversation_history)
            
            # ABAP íŠ¹í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            enhanced_prompt = build_abap_optimized_prompt(context_prompt, message)
            
            # Function Calling ì§€ì› í˜ì´ë¡œë“œ
            payload = build_enhanced_payload(model, enhanced_prompt, enable_tools)
            
            logger.info(f"Qwen2.5-Coder-14Bì— ìš”ì²­ ì „ì†¡: {message[:50]}...")
            response = await client.post(f"{OLLAMA_BASE_URL}/api/chat", json=payload)
            
            if response.status_code == 200:
                data = response.json()
                
                # AI ì‘ë‹µ ì¶”ì¶œ ë° ì²˜ë¦¬
                ai_response = extract_and_process_response(data, message)
                
                # í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦
                if ENABLE_FACT_CHECK:
                    ai_response = validate_response_accuracy(ai_response, message)
                
                logger.info(f"Qwen2.5-Coder-14B ì‘ë‹µ ì™„ë£Œ: {ai_response[:50]}...")
                return ai_response
            else:
                logger.error(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                # ë°±ì—… ëª¨ë¸ ì‹œë„
                return await fallback_model_chat(message, conversation_history)
                
    except httpx.TimeoutException:
        logger.error("Qwen2.5-Coder-14B ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        return await fallback_model_chat(message, conversation_history)
    except Exception as e:
        logger.error(f"Qwen2.5-Coder-14B í†µì‹  ì˜¤ë¥˜: {str(e)}")
        return f"AI ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}"

def build_enhanced_context_prompt(conversation_history: List[Dict]) -> str:
    """í–¥ìƒëœ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    context_prompt = ""
    if conversation_history and len(conversation_history) > 0:
        # ì¤‘ë³µ ì œê±° ë° ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
        unique_history = []
        seen_messages = set()
        
        for msg in reversed(conversation_history[-MAX_CONVERSATION_HISTORY:]):
            msg_content = msg.get('content', '').strip()
            if msg_content and msg_content not in seen_messages:
                unique_history.append(msg)
                seen_messages.add(msg_content)
                if len(unique_history) >= MAX_CONTEXT_MESSAGES:
                    break
        
        if unique_history:
            context_prompt = "=== ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ===\n"
            for msg in reversed(unique_history):
                role_display = "ğŸ‘¤ ì‚¬ìš©ì" if msg.get('role') == 'user' else "ğŸ¤– AI"
                content = msg.get('content', '')[:MAX_MESSAGE_LENGTH]
                context_prompt += f"{role_display}: {content}\n"
            context_prompt += "\n=== í˜„ì¬ ì§ˆë¬¸ ===\n"
    
    return context_prompt

def build_abap_optimized_prompt(context_prompt: str, message: str) -> str:
    """ABAP ê°œë°œ ìµœì í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    
    # ABAP ê´€ë ¨ í‚¤ì›Œë“œ ê²€ì‚¬
    abap_keywords = ['abap', 'sap', 'select', 'data:', 'form', 'function', 'report', 'table']
    is_abap_related = any(keyword in message.lower() for keyword in abap_keywords)
    
    if is_abap_related:
        return f"""ë‹¹ì‹ ì€ SAP ABAP ê°œë°œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Qwen2.5-Coder-14Bì˜ ê°•ë ¥í•œ ì½”ë”© ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ABAP ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì„¸ìš”.

**ABAP ê°œë°œ ì „ë¬¸ ê·œì¹™:**
1. **ì •í™•í•œ ABAP ë¬¸ë²•** ì‚¬ìš© - ë¬¸ë²• ì˜¤ë¥˜ ì ˆëŒ€ ê¸ˆì§€
2. **SAP ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤** ì¤€ìˆ˜ - ì„±ëŠ¥ê³¼ ìœ ì§€ë³´ìˆ˜ì„± ê³ ë ¤
3. **ë²„ì „ í˜¸í™˜ì„±** ëª…ì‹œ - ECC, S/4HANA, BTP êµ¬ë¶„
4. **ëª…ëª… ê·œì¹™** ì¤€ìˆ˜ - SAP í‘œì¤€ ë³€ìˆ˜ëª… ì‚¬ìš©
5. **ì£¼ì„ í¬í•¨** - ì½”ë“œ ì´í•´ë„ í–¥ìƒ
6. **ì—ëŸ¬ ì²˜ë¦¬** í¬í•¨ - ì˜ˆì™¸ ìƒí™© ëŒ€ë¹„
7. **ì„±ëŠ¥ ìµœì í™”** - SELECT ë¬¸ ìµœì í™”, ë‚´ë¶€ í…Œì´ë¸” íš¨ìœ¨ì  ì‚¬ìš©

**ì½”ë”© í’ˆì§ˆ ë³´ì¥:**
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” SAP í•¨ìˆ˜ë‚˜ í…Œì´ë¸”ì„ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠìŒ
- í™•ì‹¤í•˜ì§€ ì•Šì€ ABAP êµ¬ë¬¸ì€ ëŒ€ì•ˆ ì œì‹œ
- ì½”ë“œ ì„¤ëª…ê³¼ í•¨ê»˜ ì‹¤í–‰ ê°€ëŠ¥í•œ ì˜ˆì œ ì œê³µ

**ì‘ë‹µ í˜•ì‹:**
```abap
" ì£¼ì„ìœ¼ë¡œ ì„¤ëª…
" ì½”ë“œ ì‘ì„±
```

{context_prompt}

**ABAP ì§ˆë¬¸**: {message}

**ì „ë¬¸ê°€ ë‹µë³€**:"""
    else:
        return f"""ë‹¹ì‹ ì€ Qwen2.5-Coder-14B ê¸°ë°˜ì˜ ê³ ê¸‰ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°•í™”ëœ ì¶”ë¡  ëŠ¥ë ¥ê³¼ ì½”ë”© ì‹¤ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ìµœê³  í’ˆì§ˆì˜ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**ê³ ê¸‰ ë‹µë³€ ê·œì¹™:**
1. **ì •í™•ì„± ìš°ì„ ** - í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ì†”ì§íˆ ì¸ì •
2. **ë…¼ë¦¬ì  ì¶”ë¡ ** - ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì • ì œì‹œ  
3. **ì‹¤ìš©ì  ì†”ë£¨ì…˜** - ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‹µë³€
4. **ì½”ë“œ í’ˆì§ˆ** - ì£¼ì„ê³¼ ì„¤ëª…ì´ í¬í•¨ëœ ì™„ì„±ë„ ë†’ì€ ì½”ë“œ
5. **ë‹¤ì–‘í•œ ê´€ì ** - ì—¬ëŸ¬ ì ‘ê·¼ ë°©ë²• ì œì‹œ
6. **ìµœì‹  ì •ë³´** - 2025ë…„ ê¸°ì¤€ ìµœì‹  ê¸°ìˆ  ë°˜ì˜
7. **í•œêµ­ì–´ ì „ìš©** - ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ í•œêµ­ì–´ ì‚¬ìš©

**í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€:**
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì •ë³´ ì œì‘ ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤" ëª…ì‹œ
- ì¶”ì¸¡ê³¼ ì‚¬ì‹¤ êµ¬ë¶„í•˜ì—¬ ì œì‹œ

{context_prompt}

**ì§ˆë¬¸**: {message}

**ê³ ê¸‰ AI ë‹µë³€**:"""

def build_enhanced_payload(model: str, prompt: str, enable_tools: bool) -> Dict[str, Any]:
    """í–¥ìƒëœ í˜ì´ë¡œë“œ êµ¬ì„± - Function Calling ì§€ì›"""
    payload = {
        "model": model,
        "messages": [
            {
                "role": "user", 
                "content": prompt
            }
        ],
        "stream": False,
        "options": {
            "temperature": AI_TEMPERATURE,
            "top_p": AI_TOP_P,
            "repeat_penalty": AI_REPEAT_PENALTY,
            "num_predict": AI_MAX_NEW_TOKENS,
            "num_ctx": 128000,  # 128K ì»¨í…ìŠ¤íŠ¸ í™œìš©
        }
    }
    
    # Function Calling í™œì„±í™” ì‹œ ë„êµ¬ ì¶”ê°€
    if enable_tools and ENABLE_FUNCTION_CALLING:
        # ì¶”í›„ MCP ë„êµ¬ ì—°ë™ ì‹œ ì—¬ê¸°ì— tools ë°°ì—´ ì¶”ê°€
        pass
    
    return payload

def extract_and_process_response(data: Dict[str, Any], original_message: str) -> str:
    """AI ì‘ë‹µ ì¶”ì¶œ ë° í›„ì²˜ë¦¬"""
    ai_response = data.get("message", {}).get("content", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.").strip()
    
    # ABAP ì½”ë“œ ê²€ì¦
    if 'abap' in original_message.lower():
        ai_response = validate_abap_syntax(ai_response)
    
    # ì¼ë°˜ í›„ì²˜ë¦¬
    ai_response = clean_enhanced_response(ai_response)
    
    return ai_response

def validate_abap_syntax(response: str) -> str:
    """ABAP ë¬¸ë²• ê¸°ë³¸ ê²€ì¦"""
    # ê¸°ë³¸ì ì¸ ABAP ë¬¸ë²• íŒ¨í„´ ê²€ì‚¬
    common_errors = [
        (r'SELECT \* FROM', 'SELECT * FROM â†’ ì„±ëŠ¥ìƒ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.'),
        (r'INTO TABLE lt_\w+ FROM', 'ë‚´ë¶€ í…Œì´ë¸” ì„ ì–¸ì´ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'),
    ]
    
    for pattern, warning in common_errors:
        if re.search(pattern, response, re.IGNORECASE):
            response += f"\n\nâš ï¸ **ì£¼ì˜ì‚¬í•­**: {warning}"
    
    return response

def validate_response_accuracy(response: str, question: str) -> str:
    """ì‘ë‹µ ì •í™•ì„± ê²€ì¦ (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)"""
    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê²€ì‚¬
    suspicious_patterns = [
        r'ìƒˆë¡œìš´?\s*(ê¸°ìˆ |ì œí’ˆ|ê¸°ëŠ¥).*ì¶œì‹œ',
        r'ìµœê·¼ì—?\s*ë°œí‘œëœ',
        r'2025ë…„.*ì´í›„',
        r'í™•ì‹¤í•œ?\s*ì •ë³´.*ìˆìŠµë‹ˆë‹¤',
        r'ê³µì‹.*ë°œí‘œ'
    ]
    
    uncertainty_indicators = [
        'ì¶”ì¸¡', 'ì•„ë§ˆë„', 'ê°€ëŠ¥ì„±', '~ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤', 'í™•ì‹¤í•˜ì§€ ì•Šì§€ë§Œ'
    ]
    
    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê°ì§€
    for pattern in suspicious_patterns:
        if re.search(pattern, response, re.IGNORECASE):
            response = f"âš ï¸ **ì •í™•ì„± ì£¼ì˜**: ì´ ë‹µë³€ì—ëŠ” ë¶ˆí™•ì‹¤í•œ ì •ë³´ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n{response}\n\nğŸ’¡ **ê¶Œì¥ì‚¬í•­**: ì¤‘ìš”í•œ ì •ë³´ëŠ” ê³µì‹ ë¬¸ì„œë‚˜ ìµœì‹  ì†ŒìŠ¤ì—ì„œ ì¬í™•ì¸í•´ì£¼ì„¸ìš”."
            break
    
    # ë¶ˆí™•ì‹¤ì„± ì§€í‘œ í™•ì¸
    uncertainty_count = sum(1 for indicator in uncertainty_indicators if indicator in response)
    if uncertainty_count >= 2:
        response += f"\n\nğŸ¤” **ì°¸ê³ **: ì´ ë‹µë³€ì—ëŠ” ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë‹ˆ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©í•´ì£¼ì„¸ìš”."
    
    return response

def clean_enhanced_response(response: str) -> str:
    """í–¥ìƒëœ AI ì‘ë‹µ ì •ë¦¬"""
    # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
    response = re.sub(r'\n{4,}', '\n\n', response)
    response = re.sub(r'\n{3}', '\n\n', response)
    
    # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
    response = re.sub(r'[\u2605\u2606\u25a0\u25cf\u25cb\u2661\u2665\u2668\u266a\u266b]{2,}', '', response)
    
    # ì‹œì‘/ë ê³µë°± ì œê±°
    response = response.strip()
    
    return response

async def fallback_model_chat(message: str, conversation_history: List[Dict] = None) -> str:
    """ë°±ì—… ëª¨ë¸(qwen2.5-coder:7b)ë¡œ ëŒ€ì²´ ì‹¤í–‰"""
    try:
        logger.info(f"ë°±ì—… ëª¨ë¸ {FALLBACK_MODEL}ë¡œ ì „í™˜")
        return await chat_with_ollama(message, FALLBACK_MODEL, conversation_history, enable_tools=False)
    except Exception as e:
        logger.error(f"ë°±ì—… ëª¨ë¸ë„ ì‹¤íŒ¨: {str(e)}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {str(e)})"

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def is_abap_question(message: str) -> bool:
    """ABAP ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
    abap_indicators = [
        'abap', 'sap', 'select', 'data:', 'form', 'function', 'report', 'table',
        'internal table', 'ë‚´ë¶€ í…Œì´ë¸”', 'bapi', 'rfc', 'smartform', 'adobe form'
    ]
    return any(indicator in message.lower() for indicator in abap_indicators)

def get_model_status() -> Dict[str, Any]:
    """ëª¨ë¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
    return {
        "primary_model": DEFAULT_MODEL,
        "fallback_model": FALLBACK_MODEL,
        "function_calling": ENABLE_FUNCTION_CALLING,
        "mcp_enabled": ENABLE_MCP,
        "fact_check": ENABLE_FACT_CHECK,
        "max_tokens": AI_MAX_NEW_TOKENS,
        "context_window": 128000
    }

logger.info("ğŸš€ Qwen2.5-Coder-14B Chat Handler ë¡œë“œ ì™„ë£Œ")
logger.info(f"ğŸ¯ ë©”ì¸ ëª¨ë¸: {DEFAULT_MODEL}")
logger.info(f"ğŸ”§ ë°±ì—… ëª¨ë¸: {FALLBACK_MODEL}")
logger.info(f"ğŸ› ï¸ Function Calling: {'í™œì„±í™”' if ENABLE_FUNCTION_CALLING else 'ë¹„í™œì„±í™”'}")
